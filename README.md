# Machine-Learning

This is the study notes on [Machine Learning class(cs229) in Stanford](http://cs229.stanford.edu/). I also refer the materials from the class [CS6140 in Northeastern University](http://www.ccs.neu.edu/home/vip/teach/MLcourse/) to help me implement algorithms.

## Algorithms

#### 1. Supervised Learning
* Naive Bayes ([data: spambase](http://archive.ics.uci.edu/ml/datasets/Spambase))

* Linear Regression ([data: spambase](http://archive.ics.uci.edu/ml/datasets/Spambase))
	- Linear Batch Gradient Descent (Regularized & Nomal)
	- Linear Stochastic Gradient Descent
	- Linear Normal Equations (Regularized & Nomal)
	- Locally Weighted Linear Regression ([Ref: <Machine Learning in Action> Chapter 8](http://www.manning.com/pharrington/))

* Logistic Regression ([data: spambase](http://archive.ics.uci.edu/ml/datasets/Spambase))
	- Logistic Batch Gradient Descent (Regularized & Nomal)
	- Logistic Stochastic Gradient Descent
    - Smooth Stochastic Gradient Descent ([Ref: <Machine Learning in Action>(stocGradAscent1)](https://github.com/pbharrin/machinelearninginaction/blob/master/Ch05/logRegres.py))
    - Newton-Raphson([Ref: Logistic Regression by Jia Li](http://sites.stat.psu.edu/~jiali/course/stat597e/notes2/logit.pdf))

* Perceptron Algorithm ([data: spambase](http://archive.ics.uci.edu/ml/datasets/Spambase))

* Support Vector Machine
	- Sequential minimal optimization(SMO)
